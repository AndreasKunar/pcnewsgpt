#common to both .py progs
PERSIST_DIRECTORY=db
COLLECTION_NAME=langchain
EMBEDDINGS_MODEL_NAME=intfloat/multilingual-e5-large 

#ingest.py
SOURCE_DIRECTORY=source_documents
APPEND_DIRECTORY=append_documents
TEXT_SPLITTER=SpacyTextSplitter
TEXT_SPLITTER_PARAMETERS={'chunk_size':1000,'chunk_overlap':0,'pipeline':'de_core_news_lg'}

#query.py
MODEL_PATH=./models/openbuddy-llama2-13b-v11.1.Q4_K_M.gguf
MODEL_N_CTX=4096
MODEL_TEMP=0.05
MAX_TOKENS=-2
# needs edits for different hosts!
MODEL_THREADS=8
MODEL_GPU=1
MODEL_PROMPT_PER_S=24
# context settings
MAX_CONTEXT_CHUNKS=6
MAX_CONTEXT_DISTANCE=0.4049
MAX_RESORT_DISTANCE=0.05
# print details for debugging
HIDE_SOURCE=False
HIDE_SOURCE_DETAILS=False
